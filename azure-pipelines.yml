trigger:
  branches:
    include:
      - main

pool:
  name: Default
  demands:
    - agent.name -equals RSMAS-Agent

stages:
  # ===========================================
  # STAGE 1: DEPLOY TO DEV
  # ===========================================
  - stage: Deploy_Dev
    displayName: 'DEV Deployment'
    variables:
      - group: dev-dlt-vars
    jobs:
      - job: DeployDev
        displayName: 'Deploy to DEV'
        steps:
          - task: PowerShell@2
            displayName: 'Setup & Deploy'
            inputs:
              targetType: 'inline'
              script: |
                # Install CLI
                pip install databricks-cli --quiet
                
                # Configure
                $env:DATABRICKS_HOST = "$(DATABRICKS_HOST)"
                $env:DATABRICKS_TOKEN = "$(DATABRICKS_TOKEN)"
                @"
                [DEFAULT]
                host = $(DATABRICKS_HOST)
                token = $(DATABRICKS_TOKEN)
                "@ | Out-File "$env:USERPROFILE\.databrickscfg" -Encoding ASCII -Force
                
                $headers = @{Authorization="Bearer $(DATABRICKS_TOKEN)"; "Content-Type"="application/json"}
                $src = "$(Build.SourcesDirectory)"
                
                # Find all pipelines
                $pipes = Get-ChildItem $src -Filter "*.json" -Recurse | Where {$_.Directory.Name -eq "pipelines"}
                Write-Host "Found $($pipes.Count) pipeline(s)"
                
                # Deploy each pipeline
                foreach ($p in $pipes) {
                  $name = $p.BaseName
                  $folder = $p.Directory.Parent
                  Write-Host "`n=== Deploying: $name ==="
                  
                  $base = "/Workspace/Shared/DLT_Pipelines/$($folder.Name)/$name"
                  
                  # Create dirs
                  @($base, "$base/transformations", "$base/utilities", "$base/notebooks") | ForEach {
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/mkdirs" -Headers $headers -Method Post -Body (@{path=$_}|ConvertTo-Json) -ErrorAction SilentlyContinue | Out-Null
                  }
                  
                  # Update config
                  $cfg = Get-Content $p.FullName | ConvertFrom-Json
                  $cfg.catalog = "$(DLT_CATALOG)"
                  $cfg.schema = "$(DLT_SCHEMA)"
                  if (!$cfg.configuration) { $cfg | Add-Member -NotePropertyName configuration -NotePropertyValue @{} }
                  $cfg.configuration | Add-Member -NotePropertyName 'rsmas.catalog' -NotePropertyValue "$(DLT_CATALOG)" -Force
                  $cfg.configuration | Add-Member -NotePropertyName 'rsmas.schema' -NotePropertyValue "$(DLT_SCHEMA)" -Force
                  $cfg.configuration | Add-Member -NotePropertyName 'rsmas.secret.scope' -NotePropertyValue "$(DLT_SECRET_SCOPE)" -Force
                  if ($cfg.libraries) { $cfg.libraries | ForEach { if ($_.glob) { $_.glob.include = "$base/transformations/**" }}}
                  
                  $tmp = "$env:TEMP\$name.json"
                  $cfg | ConvertTo-Json -Depth 10 | Set-Content $tmp
                  
                  # Upload transformations
                  $trans = Join-Path $folder.FullName "transformations"
                  if (Test-Path $trans) {
                    Get-ChildItem $trans -Filter *.py -Recurse | ForEach {
                      $tgt = "$base/transformations/$($_.Name)"
                      $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                      Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language="PYTHON";overwrite=$true;format="SOURCE"}|ConvertTo-Json) | Out-Null
                      Write-Host "  ✅ $($_.Name)"
                    }
                  }
                  
                  # Upload utilities
                  $util = Join-Path $folder.FullName "utilities"
                  if (Test-Path $util) {
                    Get-ChildItem $util -Include *.ipynb,*.py,*.sql -Recurse | ForEach {
                      $tgt = "$base/utilities/$($_.Name)"
                      $fmt = "SOURCE"; $lang = "PYTHON"
                      if ($_.Extension -eq ".ipynb") { $fmt = "JUPYTER" }
                      if ($_.Extension -eq ".sql") { $fmt = "SQL"; $lang = "SQL" }
                      $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                      Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language=$lang;overwrite=$true;format=$fmt}|ConvertTo-Json) | Out-Null
                      Write-Host "  ✅ $($_.Name)"
                    }
                  }
                  
                  # Upload notebooks (inside pipeline folder)
                  $nb = Join-Path $folder.FullName "notebooks"
                  if (Test-Path $nb) {
                    Get-ChildItem $nb -Include *.ipynb,*.py,*.sql -Recurse | ForEach {
                      $tgt = "$base/notebooks/$($_.Name)"
                      $fmt = "SOURCE"; $lang = "PYTHON"
                      if ($_.Extension -eq ".ipynb") { $fmt = "JUPYTER" }
                      if ($_.Extension -eq ".sql") { $fmt = "SQL"; $lang = "SQL" }
                      $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                      Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language=$lang;overwrite=$true;format=$fmt}|ConvertTo-Json) | Out-Null
                      Write-Host "  ✅ $($_.Name)"
                    }
                  }
                  
                  # Create/update pipeline
                  $list = Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/pipelines" -Headers $headers -Method Get
                  $existing = $list.statuses | Where {$_.name -eq $name} | Select -First 1
                  if ($existing) {
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/pipelines/$($existing.pipeline_id)" -Headers $headers -Method Put -Body (Get-Content $tmp -Raw) | Out-Null
                    Write-Host "  ✅ Updated pipeline"
                  } else {
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/pipelines" -Headers $headers -Method Post -Body (Get-Content $tmp -Raw) | Out-Null
                    Write-Host "  ✅ Created pipeline"
                  }
                }
                
                # Find standalone notebooks (outside pipeline folders)
                $pipelinePaths = $pipes | ForEach { $_.Directory.Parent.FullName }
                $nbFolders = Get-ChildItem $src -Directory -Recurse | Where {
                  $_.Name -in @("notebooks","explorations","analysis") -and
                  -not ($pipelinePaths | Where { $_.FullName.StartsWith($_) })
                }
                
                Write-Host "`nFound $($nbFolders.Count) standalone notebook folder(s)"
                
                # Deploy standalone notebooks
                foreach ($nbf in $nbFolders) {
                  Write-Host "`n=== Deploying: $($nbf.Parent.Name)/$($nbf.Name) ==="
                  $base = "/Workspace/Shared/Notebooks/$($nbf.Parent.Name)/$($nbf.Name)"
                  
                  # Create dir
                  Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/mkdirs" -Headers $headers -Method Post -Body (@{path=$base}|ConvertTo-Json) -ErrorAction SilentlyContinue | Out-Null
                  
                  # Upload notebooks
                  Get-ChildItem $nbf.FullName -Include *.ipynb,*.py,*.sql -Recurse | ForEach {
                    $tgt = "$base/$($_.Name)"
                    $fmt = "SOURCE"; $lang = "PYTHON"
                    if ($_.Extension -eq ".ipynb") { $fmt = "JUPYTER" }
                    if ($_.Extension -eq ".sql") { $fmt = "SQL"; $lang = "SQL" }
                    $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language=$lang;overwrite=$true;format=$fmt}|ConvertTo-Json) | Out-Null
                    Write-Host "  ✅ $($_.Name)"
                  }
                }
                
                Write-Host "`n✅ DEV deployment complete!"

  # ===========================================
  # STAGE 2: MANUAL APPROVAL
  # ===========================================
  - stage: Approval
    displayName: 'Approval for TEST'
    dependsOn: Deploy_Dev
    jobs:
      - job: Approve
        displayName: 'Wait for Approval'
        pool: server
        timeoutInMinutes: 1440
        steps:
          - task: ManualValidation@0
            inputs:
              notifyUsers: 'peram.monica@outlook.com'
              instructions: |
                DEV deployment done. 
                Verify and approve to deploy to TEST.
              onTimeout: 'reject'

  # ===========================================
  # STAGE 3: DEPLOY TO TEST
  # ===========================================
  - stage: Deploy_Test
    displayName: 'TEST Deployment'
    dependsOn: Approval
    variables:
      - group: test-dlt-vars
    jobs:
      - job: DeployTest
        displayName: 'Deploy to TEST'
        steps:
          - task: PowerShell@2
            displayName: 'Setup & Deploy'
            inputs:
              targetType: 'inline'
              script: |
                # Install CLI
                pip install databricks-cli --quiet
                
                # Configure
                $env:DATABRICKS_HOST = "$(DATABRICKS_HOST)"
                $env:DATABRICKS_TOKEN = "$(DATABRICKS_TOKEN)"
                @"
                [DEFAULT]
                host = $(DATABRICKS_HOST)
                token = $(DATABRICKS_TOKEN)
                "@ | Out-File "$env:USERPROFILE\.databrickscfg" -Encoding ASCII -Force
                
                $headers = @{Authorization="Bearer $(DATABRICKS_TOKEN)"; "Content-Type"="application/json"}
                $src = "$(Build.SourcesDirectory)"
                
                # Find all pipelines
                $pipes = Get-ChildItem $src -Filter "*.json" -Recurse | Where {$_.Directory.Name -eq "pipelines"}
                Write-Host "Found $($pipes.Count) pipeline(s)"
                
                # Deploy each pipeline
                foreach ($p in $pipes) {
                  $name = $p.BaseName
                  $folder = $p.Directory.Parent
                  Write-Host "`n=== Deploying: $name ==="
                  
                  $base = "/Workspace/Shared/DLT_Pipelines/$($folder.Name)/$name"
                  
                  # Create dirs
                  @($base, "$base/transformations", "$base/utilities", "$base/notebooks") | ForEach {
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/mkdirs" -Headers $headers -Method Post -Body (@{path=$_}|ConvertTo-Json) -ErrorAction SilentlyContinue | Out-Null
                  }
                  
                  # Update config
                  $cfg = Get-Content $p.FullName | ConvertFrom-Json
                  $cfg.catalog = "$(DLT_CATALOG)"
                  $cfg.schema = "$(DLT_SCHEMA)"
                  if (!$cfg.configuration) { $cfg | Add-Member -NotePropertyName configuration -NotePropertyValue @{} }
                  $cfg.configuration | Add-Member -NotePropertyName 'rsmas.catalog' -NotePropertyValue "$(DLT_CATALOG)" -Force
                  $cfg.configuration | Add-Member -NotePropertyName 'rsmas.schema' -NotePropertyValue "$(DLT_SCHEMA)" -Force
                  $cfg.configuration | Add-Member -NotePropertyName 'rsmas.secret.scope' -NotePropertyValue "$(DLT_SECRET_SCOPE)" -Force
                  if ($cfg.libraries) { $cfg.libraries | ForEach { if ($_.glob) { $_.glob.include = "$base/transformations/**" }}}
                  
                  $tmp = "$env:TEMP\$name.json"
                  $cfg | ConvertTo-Json -Depth 10 | Set-Content $tmp
                  
                  # Upload transformations
                  $trans = Join-Path $folder.FullName "transformations"
                  if (Test-Path $trans) {
                    Get-ChildItem $trans -Filter *.py -Recurse | ForEach {
                      $tgt = "$base/transformations/$($_.Name)"
                      $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                      Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language="PYTHON";overwrite=$true;format="SOURCE"}|ConvertTo-Json) | Out-Null
                      Write-Host "  ✅ $($_.Name)"
                    }
                  }
                  
                  # Upload utilities
                  $util = Join-Path $folder.FullName "utilities"
                  if (Test-Path $util) {
                    Get-ChildItem $util -Include *.ipynb,*.py,*.sql -Recurse | ForEach {
                      $tgt = "$base/utilities/$($_.Name)"
                      $fmt = "SOURCE"; $lang = "PYTHON"
                      if ($_.Extension -eq ".ipynb") { $fmt = "JUPYTER" }
                      if ($_.Extension -eq ".sql") { $fmt = "SQL"; $lang = "SQL" }
                      $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                      Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language=$lang;overwrite=$true;format=$fmt}|ConvertTo-Json) | Out-Null
                      Write-Host "  ✅ $($_.Name)"
                    }
                  }
                  
                  # Upload notebooks (inside pipeline folder)
                  $nb = Join-Path $folder.FullName "notebooks"
                  if (Test-Path $nb) {
                    Get-ChildItem $nb -Include *.ipynb,*.py,*.sql -Recurse | ForEach {
                      $tgt = "$base/notebooks/$($_.Name)"
                      $fmt = "SOURCE"; $lang = "PYTHON"
                      if ($_.Extension -eq ".ipynb") { $fmt = "JUPYTER" }
                      if ($_.Extension -eq ".sql") { $fmt = "SQL"; $lang = "SQL" }
                      $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                      Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language=$lang;overwrite=$true;format=$fmt}|ConvertTo-Json) | Out-Null
                      Write-Host "  ✅ $($_.Name)"
                    }
                  }
                  
                  # Create/update pipeline
                  $list = Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/pipelines" -Headers $headers -Method Get
                  $existing = $list.statuses | Where {$_.name -eq $name} | Select -First 1
                  if ($existing) {
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/pipelines/$($existing.pipeline_id)" -Headers $headers -Method Put -Body (Get-Content $tmp -Raw) | Out-Null
                    Write-Host "  ✅ Updated pipeline"
                  } else {
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/pipelines" -Headers $headers -Method Post -Body (Get-Content $tmp -Raw) | Out-Null
                    Write-Host "  ✅ Created pipeline"
                  }
                }
                
                # Find standalone notebooks (outside pipeline folders)
                $pipelinePaths = $pipes | ForEach { $_.Directory.Parent.FullName }
                $nbFolders = Get-ChildItem $src -Directory -Recurse | Where {
                  $_.Name -in @("notebooks","explorations","analysis") -and
                  -not ($pipelinePaths | Where { $_.FullName.StartsWith($_) })
                }
                
                Write-Host "`nFound $($nbFolders.Count) standalone notebook folder(s)"
                
                # Deploy standalone notebooks
                foreach ($nbf in $nbFolders) {
                  Write-Host "`n=== Deploying: $($nbf.Parent.Name)/$($nbf.Name) ==="
                  $base = "/Workspace/Shared/Notebooks/$($nbf.Parent.Name)/$($nbf.Name)"
                  
                  # Create dir
                  Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/mkdirs" -Headers $headers -Method Post -Body (@{path=$base}|ConvertTo-Json) -ErrorAction SilentlyContinue | Out-Null
                  
                  # Upload notebooks
                  Get-ChildItem $nbf.FullName -Include *.ipynb,*.py,*.sql -Recurse | ForEach {
                    $tgt = "$base/$($_.Name)"
                    $fmt = "SOURCE"; $lang = "PYTHON"
                    if ($_.Extension -eq ".ipynb") { $fmt = "JUPYTER" }
                    if ($_.Extension -eq ".sql") { $fmt = "SQL"; $lang = "SQL" }
                    $b64 = [Convert]::ToBase64String([IO.File]::ReadAllBytes($_.FullName))
                    Invoke-RestMethod "$(DATABRICKS_HOST)/api/2.0/workspace/import" -Headers $headers -Method Post -Body (@{path=$tgt;content=$b64;language=$lang;overwrite=$true;format=$fmt}|ConvertTo-Json) | Out-Null
                    Write-Host "  ✅ $($_.Name)"
                  }
                }
                
                Write-Host "`n✅ TEST deployment complete!"
