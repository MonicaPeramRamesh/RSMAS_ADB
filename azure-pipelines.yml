trigger:
- main

pool:
  name: Default
  demands:
    - agent.name -equals RSMAS-Agent

variables:
- group: test-dlt-vars  # Databricks credentials & target catalog/schema

stages:

# =====================================================
# Stage 1️⃣ Build
# =====================================================
- stage: Build
  displayName: "Build DLT Artifact"
  jobs:
  - job: BuildJob
    displayName: "Build DLT Artifact"
    pool:
      name: Default
      demands:
        - agent.name -equals RSMAS-Agent
    steps:

    - script: |
        python --version
        pip --version
      displayName: "Verify Python"

    - script: |
        echo "✅ Dependencies installed"
      displayName: "Install dependencies"

    - publish: .
      artifact: DLT_Artifact
      displayName: "Publish DLT Artifact"

# =====================================================
# Stage 2️⃣ Deploy
# =====================================================
- stage: Deploy
  displayName: "Deploy All DLT Pipelines & Notebooks"
  dependsOn: Build
  jobs:
  - job: DeployJob
    displayName: "Deploy DLT Pipelines & Notebooks"
    pool:
      name: Default
      demands:
        - agent.name -equals RSMAS-Agent
    steps:

    # Download the artifact
    - download: current
      artifact: DLT_Artifact
      displayName: "Download DLT Artifact"

    # Deploy all JSON pipeline files
    - task: PowerShell@2
      displayName: "Deploy all DLT Pipelines"
      inputs:
        targetType: 'inline'
        script: |
          $artifactPath = "$(Pipeline.Workspace)/DLT_Artifact"
          $pipelineFolder = Join-Path $artifactPath "pipelines"

          if (-Not (Test-Path $pipelineFolder)) {
              Write-Error "Pipeline folder '$pipelineFolder' not found!"
              exit 1
          }

          $jsonFiles = Get-ChildItem -Path $pipelineFolder -Filter *.json
          foreach ($file in $jsonFiles) {
              Write-Host "Updating pipeline JSON: $($file.FullName)"
              python "$artifactPath/scripts/update_pipeline_json.py" --file $file.FullName --catalog $(DLT_CATALOG) --schema $(DLT_SCHEMA) --secret_scope $(DLT_SECRET_SCOPE)

              $pipelineJson = Get-Content $file.FullName -Raw
              $pipelineName = (ConvertFrom-Json $pipelineJson).name

              # Try to create the pipeline
              $response = curl -s -o $null -w "%{http_code}" -X POST `
                  -H "Authorization: Bearer $(DATABRICKS_TOKEN)" `
                  -H "Content-Type: application/json" `
                  -d $pipelineJson `
                  https://$(DATABRICKS_HOST)/api/2.0/pipelines

              if ($response -eq "409") {
                  Write-Host "Pipeline '$pipelineName' exists, updating..."
                  $pipelinesList = curl -s -H "Authorization: Bearer $(DATABRICKS_TOKEN)" https://$(DATABRICKS_HOST)/api/2.0/pipelines | ConvertFrom-Json
                  $pipelineId = ($pipelinesList.pipelines | Where-Object { $_.name -eq $pipelineName }).pipeline_id
                  
                  curl -s -X PATCH `
                      -H "Authorization: Bearer $(DATABRICKS_TOKEN)" `
                      -H "Content-Type: application/json" `
                      -d $pipelineJson `
                      https://$(DATABRICKS_HOST)/api/2.0/pipelines/$pipelineId
              }
          }

    # Deploy all notebooks
    - task: PowerShell@2
      displayName: "Deploy all Notebooks"
      inputs:
        targetType: 'inline'
        script: |
          $artifactPath = "$(Pipeline.Workspace)/DLT_Artifact"
          $notebooks = Get-ChildItem -Path $artifactPath -Recurse -Filter *.ipynb
          foreach ($nb in $notebooks) {
              $relPath = $nb.FullName.Substring($artifactPath.Length + 1) -replace '\\','/'
              $targetPath = "/Repos/RSMAS_ADB/dlt/$relPath"
              Write-Host "Deploying $($nb.FullName) -> $targetPath"
              
              $content = [Convert]::ToBase64String([System.IO.File]::ReadAllBytes($nb.FullName))
              
              curl -s -X POST `
                -H "Authorization: Bearer $(DATABRICKS_TOKEN)" `
                -H "Content-Type: application/json" `
                -d (@"
{
  "path": "$targetPath",
  "language": "PYTHON",
  "overwrite": true,
  "content": "$content"
}
"@) `
                https://$(DATABRICKS_HOST)/api/2.0/workspace/import
          }
