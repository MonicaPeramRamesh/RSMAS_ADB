trigger:
- main

pool:
  vmImage: ubuntu-latest

variables:
- group: dev-dlt-vars

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.x'

- script: |
    pip install databricks-cli jq
    databricks configure --token <<< "$(DATABRICKS_HOST)\n$(DATABRICKS_TOKEN)"
  displayName: Configure Databricks CLI

- script: |
    for file in dlt/**/pipelines/*.json; do
      echo "ðŸš€ Deploying $file"

      python scripts/update_pipeline_json.py \
        --file "$file" \
        --catalog "$(DLT_CATALOG)" \
        --schema "$(DLT_SCHEMA)" \
        --secret_scope "$(DLT_SECRET_SCOPE)"

      PIPELINE_NAME=$(jq -r '.name' "$file")

      PIPELINE_ID=$(databricks pipelines list \
        | jq -r ".[] | select(.name==\"$PIPELINE_NAME\") | .pipeline_id")

      if [ -z "$PIPELINE_ID" ]; then
        databricks pipelines create --json-file "$file"
        echo "âœ… Created: $PIPELINE_NAME"
      else
        databricks pipelines update \
          --pipeline-id "$PIPELINE_ID" \
          --json-file "$file"
        echo "ðŸ” Updated: $PIPELINE_NAME"
      fi
    done
  displayName: Deploy ALL DLT pipelines
